# Plan de Dise√±o Profesional para "ComputeNodes" (Blender 5.0+ Addon)

> [!CAUTION]
> ## ‚ö†Ô∏è DEPRECATED ‚Äî See [GEMINI.md](./GEMINI.md)
> This document is outdated. The authoritative design documentation is now in **GEMINI.md**.
> This file is kept for historical reference only.

---

> [!IMPORTANT]
> ## üîÑ ACTUALIZACI√ìN ARQUITECT√ìNICA CR√çTICA (Diciembre 2025)
> 
> **Paradigma Field-Based implementado** - Similar a Geometry Nodes Fields:
> 
> | Antes | Ahora |
> |-------|-------|
> | Output ten√≠a width/height | Output **sin resoluci√≥n**, solo recibe Texture |
> | Resize aceptaba Color | Resize **Texture‚ÜíTexture** |
> | Position usaba gl_WorkGroups | Position usa **u_dispatch uniforms** del Rasterize |
> 
> **Regla fundamental**: `Field ‚Üí Texture` SOLO via **Rasterize**. Output NO materializa.
> 
> Ver `hoja_de_dise√±o_compute_nodes.md` Secci√≥n 2.5 para detalles completos.

---

## **Introducci√≥n y Estado Actual del MVP**

El addon **ComputeNodes** es un prototipo de sistema de **nodos de c√≥mputo GPU** para Blender 4.x/5.x, enfocado en procesar im√°genes 2D mediante _compute shaders_. Emplea un **√°rbol de nodos personalizado** (ComputeNodeTree) con nodos que generan c√≥digo GLSL y ejecutan en GPU. Actualmente, el MVP soporta operaciones matem√°ticas b√°sicas, texturas procedurales (ruido, voronoi, etc.), manipulaci√≥n de vectores y color, bucles sencillos y E/S de im√°genes. La arquitectura interna se basa en una representaci√≥n intermedia (_IR_) SSA con opcodes definidos, un planificador de _passes_ de c√≥mputo y un ejecutor que usa la API GPU de Blender.

**Limitaciones actuales:** El dise√±o MVP presenta varias decisiones simplificadas que debemos revisar y mejorar. Por ejemplo, **solo maneja im√°genes 2D en una resoluci√≥n global fija** (tomada del primer nodo de salida o de la resoluci√≥n de render por defecto)[\[1\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L46-L55)[\[2\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L56-L64), no contempla directamente datos 1D/3D ni m√∫ltiples resoluciones en un mismo gr√°fico. La implementaci√≥n de bucles est√° **hardcodeada** para un caso muy espec√≠fico (un acumulador escalar)[\[3\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L801-L810), y algunos nodos/recursos se manejan con suposiciones fr√°giles (e.g. el nodo Output asume un _target_ de imagen conectado, pero su interfaz UI solo expone un socket de color). Adem√°s, ciertas partes del IR/c√≥digo est√°n incompletas o son inconsistentes (p. ej. manejo de multi-salida, nodos de escritura de imagen, etc.), lo que ofrece oportunidades claras de refactorizaci√≥n.

A continuaci√≥n se presenta un plan de dise√±o detallado que eleva este MVP hacia un nivel comparable con Houdini **Copernicus** (el nuevo contexto de composici√≥n de Houdini 20.5/21), abordando soporte de **kernels 1D/2D/3D**, bucles avanzados, nuevos tipos de datos (part√≠culas, vol√∫menes, etc.), nodos personalizables por el usuario, mejoras de arquitectura IR, manejo robusto de dominios/resoluciones, y una UX consistente con Blender. Cada recomendaci√≥n se justifica t√©cnicamente, se√±alando riesgos y consideraciones de implementaci√≥n.

## **Soporte para Kernels 1D, 2D y 3D (evaluaci√≥n de SSBO en Blender 2025)**

Actualmente ComputeNodes asume kernels 2D (im√°genes bidimensionales) y lanza el _compute shader_ en un dominio 2D fijo (anchura/altura). Para alcanzar un nivel "Copernicus" debemos **extender el soporte a datos 1D y 3D**, lo que incluye im√°genes 1D (l√≠neas de p√≠xeles), vol√∫menes 3D, o buffers arbitrarios. Proponemos lo siguiente:

- **Generalizaci√≥n de recursos de imagen:** Redise√±ar la clase de recurso ImageDesc (o crear un ResourceDesc gen√©rico) para incluir el **tipo de dimensionalidad** (1D, 2D, 3D). Esto permitir√° que el IR diferencie entre, por ejemplo, image1D, image2D e image3D. En la generaci√≥n de c√≥digo GLSL, usaremos la dimensionalidad apropiada al declarar y acceder a la imagen. Por ejemplo, una imagen 3D se declarar√° como image3D y se indexar√° con coordenadas (x,y,z), mientras que una 1D usar√≠a image1D con √≠ndice x. Actualmente el c√≥digo asume image2D uniformemente[\[4\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/codegen/glsl.py#L88-L96), por lo que habr√≠a que hacerlo dependiente del tipo de recurso.
- **Ajuste del lanzamiento (_dispatch_) del c√≥mputo:** Con kernels 1D/3D, el tama√±o de grupo de c√≥mputo y el n√∫mero de grupos lanzados cambiar√°n. Blender permite invocar gpu.compute.dispatch(shader, nx, ny, nz) con grupos en X, Y y Z[\[5\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py#L140-L148)[\[6\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py#L150-L156). Para una imagen 1D, definir√≠amos ny=nz=1 y nx = ceil(longitud/local_size_x). Para una 3D, calcularemos los grupos en X, Y, Z seg√∫n la profundidad. Es importante coordinar esto con la directiva layout(local_size_x, local_size_y, local_size_z) en el shader. Por ejemplo, podr√≠amos usar local_size = (8,8,1) para 2D y (4,4,4) para 3D, seg√∫n convenga. El _planner_ deber√° asignar a cada **ComputePass** una dimensionalidad de ejecuci√≥n (derivada de los recursos que procesa). Inicialmente podemos restringir: _todas_ las ops de un pass comparten la misma dimensionalidad (p.ej., si un pass escribe un volumen 3D, ejecutamos en 3D). Si se mezcla 2D y 3D en un mismo gr√°fico, el planificador debe segmentar en pases separados cuando cambie la dimensionalidad (extensi√≥n de la l√≥gica de hazard actual). En el c√≥digo ya se prev√© dividir pases si cambian "requerimientos de dispatch"[\[7\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/planner/scheduler.py#L20-L28), funcionalidad que implementaremos para casos 1D/3D.
- **Buffers y SSBOs:** Para datos 1D no-imagen (por ejemplo, listas de part√≠culas, curvas de valores, etc.), lo ideal es usar **SSBOs (Shader Storage Buffer Objects)** por su flexibilidad para almacenar arrays arbitrarios en shaders. Sin embargo, debemos verificar la viabilidad en Blender 5.0. A diciembre de 2025, la API gpu de Blender sigue madurando; en discusiones de desarrolladores se indica el deseo de exponer SSBOs pero a√∫n no es claro si hay soporte completo[\[8\]](https://devtalk.blender.org/t/suggestions-feedback-on-the-extensions-for-the-gpu-module/17706/79?u=fclem#:~:text=Suggestions%20%2F%20feedback%20on%20the,sake%2C%20maybe%20something%20like). En ausencia de una envoltura directa de SSBO en Python, proponemos dos estrategias:
- **Emular buffers con texturas 1D:** Utilizar una textura 1D (por ejemplo RGBA32F) como contenedor de datos arbitrarios. Cada "elemento" del buffer puede ocupar uno o varios texels (p.ej., un punto 3D con atributos podr√≠a almacenarse en varios p√≠xeles). Luego, un _shader_ puede acceder a ellos v√≠a funciones de muestreo (texelFetch o imageLoad en una imagen 1D). Esto aprovecha la API existente (gpu.texture.from_image para im√°genes, o GPUTexture((N,1), format) para texturas internas). La limitaci√≥n es la cuantizaci√≥n a 4 componentes por texel; para estructuras m√°s complejas habr√≠a que repartir en m√∫ltiples texturas o en m√°s texels consecutivos.
- **Usar uniform buffers para peque√±os conjuntos:** Blender s√≠ permite uniformes del shader, pero est√°n limitados en tama√±o. Para datos peque√±os (e.g. vectores de constantes), se podr√≠a concebir un nodo que suba un array como UBO (Uniform Buffer Object). Aun as√≠, para cientos o miles de elementos esto no escala.

Cuando Blender exponga SSBOs en Python (posiblemente v√≠a gpu.types.GPUStorageBuffer en un futuro), podremos mapear directamente un recurso IR tipo BUFFER a un SSBO GLSL (ej. layout(std430, binding=X) buffer BufName { ... };). Recomendamos dise√±ar la abstracci√≥n de **ResourceType** en el IR con esta futura incorporaci√≥n en mente: por ejemplo, a√±adir ResourceType.BUFFER y opcodes IR BUFFER_READ/WRITE (ya definidos en el MVP[\[9\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/ir/ops.py#L100-L105)) que luego el generador de c√≥digo traduzca a accesos SSBO cuando sea posible. En la ejecuci√≥n, ComputeExecutor necesitar√≠a crear/gestionar dichos buffers an√°logamente a las texturas. Hasta entonces, la soluci√≥n de textura1D nos permite soportar casos importantes (part√≠culas, arrays) de forma transparente al usuario - este simplemente ver√° un _socket_ de tipo "Buffer" o similar.

- **Soporte de texturas 3D (vol√∫menes):** Si tratamos vol√∫menes de densidad u otros grids 3D, aprovecharemos las texturas 3D de OpenGL. Blender **deber√≠a** soportar la creaci√≥n de GPUTextures 3D (dado que OpenGL 4.3 lo permite y Vulkan tambi√©n). Confirmaremos v√≠a gpu.types.GPUTexture((size_x, size_y, size_z), format=‚Ä¶) si es viable. En caso afirmativo, TextureManager.ensure_internal_texture puede ampliarse para manejar la dimensi√≥n extra. El IR ImageDesc para un volumen contendr√° size=(X,Y,Z). En GLSL generaremos image3D. Un aspecto a vigilar es el **filtro**: si en un shader 2D se usa un volumen 3D, ¬øc√≥mo se muestrea? Podr√≠amos restringir cada shader a una dimensi√≥n uniformemente (as√≠, un volumen solo se procesa en un pass 3D). Para convertir un volumen a im√°genes 2D (slices) o viceversa, se ofrecer√≠an nodos especializados (p. ej. un nodo que extrae un corte 2D de un volumen).

**Conclusi√≥n de kernels 1D/2D/3D:** Con estos cambios, ComputeNodes podr√° ejecutar **kernels de distinta dimensionalidad**, aline√°ndose con Houdini Copernicus donde los nodos de imagen se consideran esencialmente "vol√∫menes 2D" (lo que hace natural extender a vol√∫menes 3D y datos 1D)[\[10\]](https://tokeru.com/cgwiki/HoudiniCops.html#:~:text=%2A%20New%20cops%20flow%20left,back%20to%20the%20viewport%20live). El plan prioriza usar texturas 1D/3D como an√°logo a SSBO/volumen mientras la API no provea algo espec√≠fico, minimizando la dependencia en caracter√≠sticas futuras pero dejando abierta la extensibilidad a SSBOs reales cuando est√©n disponibles.

## **Bucles Avanzados y "Repeat Zones" (Ping-Pong, Cascada de Resoluciones)**

El MVP implementa una forma b√°sica de bucle mediante los nodos **Repeat Zone (Input/Output)**, pero con limitaciones: solo maneja un valor escalar "Current Value" que itera, asumiendo un bucle lineal sobre todos los p√≠xeles con un n√∫mero fijo de iteraciones[\[11\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/control_flow.py#L114-L123)[\[12\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/control_flow.py#L132-L139). Actualmente, al extraer el gr√°fico se inserta directamente una secuencia IR con opcodes LOOP_START y LOOP_END que engloban las operaciones internas[\[3\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L801-L810)[\[13\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L838-L847). Para robustecer este sistema necesitamos:

- **Bucles con m√∫ltiples variables y tipos:** En la versi√≥n actual, RepeatInput produce dos salidas: Iteration (int) y Current Value (float), y RepeatOutput acepta Next Value (float)[\[14\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/control_flow.py#L115-L123)[\[12\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/control_flow.py#L132-L139). Esto est√° _hardcodeado_ para manejar esencialmente una suma acumulativa de un escalar. Queremos que un bucle pueda transportar **cualquier tipo de dato** (im√°genes, vectores, estructuras) de una iteraci√≥n a la siguiente, similar a los "feedback loops" en sistemas de nodos avanzados. Para lograrlo:
- Redise√±aremos los nodos de bucle para que soporten **m√∫ltiples pares de sockets** de entrada/salida en Repeat Input/Output. Por ejemplo, el usuario podr√≠a configurar un Repeat Input con N "Initial" entradas y N "Current" salidas (hoy fijo en 1 par), permitiendo varias variables de estado. Podemos exponer un UI din√°mico: un bot√≥n "+" para agregar otro par de sockets al loop (similar a c√≥mo funciona el nodo _Combine_ en Geometry Nodes).
- **Tipos de datos arbitrarios:** en lugar de forzar float, las salidas del Repeat Input deben heredar el tipo de sus iniciales. Si se quiere iterar una imagen, el socket "Initial Image" producir√° un "Current Image". En IR, eso implicar√° que LOOP_START acepte valores de tipo _handle_ (imagen) adem√°s de floats. El IR actual marca LOOP_START/END sin distinci√≥n de tipo - podr√≠amos extender la sem√°ntica para manejar vectores o handles. En la pr√°ctica, un **bucle sobre im√°genes** ser√≠a un ping-pong buffer trivial (alternar dos texturas) a menos que combinemos con ping-pong (ver siguiente punto).
- El sistema IR/Codegen deber√° soportar outputs m√∫ltiples de LOOP_START. Ahora mismo ya a√±ade dos outputs (valor actual y √≠ndice) manualmente[\[15\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L813-L822); generalizarlo a N outputs es factible: crear M outputs SSA para LOOP_START (uno por variable) m√°s el √≠ndice, y en LOOP_END consumir M+1 valores (las "Next" de cada variable m√°s el acumulador previo). Ajustaremos los _emitter_ GLSL para generar un bucle for donde se actualizan todas las variables simult√°neamente.
- **Patr√≥n Ping-Pong (doble buffer):** Muchas iteraciones en procesamiento de im√°genes alternan escribir y leer de dos buffers para evitar sobreescribir datos que se necesitan en el siguiente paso. Queremos exponer esta capacidad al usuario. Una forma amigable es un **nodo especial de Ping-Pong** o una opci√≥n en los nodos Repeat:
- **Opci√≥n A:** Introducir un nodo PingPong Loop que internamente se configure con dos im√°genes de trabajo. El usuario provee la imagen inicial A, y dentro del bucle las operaciones escriben en B; al final de cada iteraci√≥n, se intercambian (lo que era B pasa a A para la siguiente iteraci√≥n). Este nodo podr√≠a ser un meta-nodo que genere el IR apropiado (similar a Repeat, pero con dos recursos intercambiables).
- **Opci√≥n B:** Permitir que el par RepeatInput/Output detecte recursos de tipo imagen y autom√°ticamente active modo ping-pong. Por ejemplo, si la "Current Value" es de tipo imagen, podemos en IR asignarle dos ImageDesc de salida e ir alternando en LOOP_END: un ciclo escribe a la textura1, el siguiente a textura2. Esto requiere que el IR LOOP_START/END sepan de doble-buffering. Alternativamente, modelar ping-pong expl√≠citamente: Podr√≠amos introducir opcodes LOOP_SWAP o aprovechar ResourceAccess.READ_WRITE en el descriptor para indicar que se usa en ambos roles. Una implementaci√≥n viable: **mantener dos √≠ndices de recurso** en el IR para la misma entidad l√≥gica y conmutarlos en cada iteraci√≥n mediante una operaci√≥n especial (p.ej., un XOR de √≠ndice en GLSL).
- Desde el punto de vista del _shader_, implementar ping-pong puramente dentro de un solo shader es complicado (porque un solo dispatch no puede "alternar" buffers iterativamente, salvo usando barreras y grupos de trabajo que reinvocar√≠amos manualmente, lo cual sale del modelo). Es m√°s sencillo concebir que **cada iteraci√≥n es un pass separado**: el _scheduler_ podr√≠a "desenrollar" un ping-pong loop en passes alternos (aunque con N iteraciones fija, se puede generar 2N passes alternando recursos, pero eso no escala si N es grande). En su lugar, se podr√≠a simplemente ejecutar el mismo compute shader N veces desde Python, alternando la vinculaci√≥n de texturas. **Recomendaci√≥n:** Para ping-pong de iteraciones muchas, usar la v√≠a de _dispatch_ m√∫ltiple (con peque√±as modificaciones al ComputeExecutor para bucles), en lugar de intentar meterlo todo en un solo shader con l√≥gica de √≠ndice. Esto implicar√≠a que al extraer IR de un PingPong Loop, detectamos el patr√≥n y no generamos un loop GLSL, sino un **bloque repetitivo en CPU** que realiza dispatch N veces. Se perder√≠a algo de paralelismo global, pero se gana en simplicidad y menor consumo de VRAM (solo dos buffers reutilizados).
- De cara al usuario, habilitar ping-pong significa permitir algoritmos iterativos como blur difusivo, erosiones/dilataciones repetidas, etc., donde sin esta t√©cnica se requerir√≠an duplicar manualmente nodos para simular iteraciones.
- **Cascada de resoluciones (multi-scale):** Este concepto implica procesar la imagen en m√∫ltiples escalas (por ejemplo, generar una pir√°mide Gaussiana, procesar de baja a alta resoluci√≥n). En Houdini/Nuke se suele lograr con nodos de _scale_ combinados con bucles. Para incluirlo:
- A√±adir un nodo (o integrar en Repeat) que **var√≠e la resoluci√≥n en cada iteraci√≥n**. Por ejemplo, un nodo Loop (Multi-Scale) podr√≠a tener factores de escala (p.ej., 50% cada iteraci√≥n). Internamente, cada iteraci√≥n crear√≠a/copiar√≠a la imagen a una resoluci√≥n reducida. Implementarlo dentro de un solo shader es complejo; lo natural es orquestarlo a nivel de passes:
  - Estrategia: Suponer que en la primera iteraci√≥n usas la imagen full res, en la segunda una reducida al 50%, etc. El _ComputeExecutor_ podr√≠a reconfigurar el tama√±o de dispatch y texturas para cada iteraci√≥n. Esto requiere poder **recrear o redimensionar GPUTextures sobre la marcha**. Una forma ser√≠a crear desde el inicio todas las texturas de las resoluciones necesarias (seg√∫n un factor o una lista dada) y almacenarlas en TextureManager. El bucle ir√≠a asignando val_target.size diferente antes de cada dispatch.
  - Alternativamente, podr√≠amos generar en IR un _tree unrolling_ de resoluciones: ej. un loop de 3 iteraciones a 100%,50%,25% se convierte en tres subgr√°ficos conectados donde cada uno hace un resize + proceso. Sin embargo, eso pierde generalidad y elegancia.
- Quiz√° es m√°s sencillo ofrecer nodos b√°sicos de **Scale/Resize** (p. ej. Scale Image con factor o resoluci√≥n absoluta) y permitir al usuario combinarlos con loops manualmente. Un nodo _Scale_ generar√≠a en IR una operaci√≥n que crea un nuevo ImageDesc con dimensiones diferentes y llena sus p√≠xeles muestreando la imagen de entrada (posiblemente usando hardware bilinear via sampler). De hecho, implementar un _downscale_ eficiente puede requerir un shader espec√≠fico (no trivial con un solo imageStore por pixel; podr√≠amos aprovechar texturas y sampler2D con filtrado si Blender GPU lo permite en compute).
- Dado el tiempo, recomendamos inicialmente una **soluci√≥n expl√≠cita**: incluir un nodo _Resize_ o _Resample_ para que el usuario construya la cascada manualmente (como: Imagen -> Resize 50% -> ...). M√°s adelante, podr√≠amos a√±adir azucar sint√°ctico mediante un tipo especial de loop que incorpore internamente ese resize cada iteraci√≥n.
- **Integraci√≥n con IR y planner:** Los bucles actuales se representan en IR con OpCode.LOOP_START/END[\[16\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/ir/ops.py#L78-L86) y manejan la iteraci√≥n internamente en el shader (se genera un for loop). Con las mejoras propuestas, especialmente para ping-pong y multi-res, puede que optemos por resolver ciertas repeticiones a nivel de _scheduler_ (como m√∫ltiples passes en serie). Esto significa que _no siempre utilizaremos un loop GLSL interno_; en ocasiones, el bucle de alto nivel se traducir√° a ejecutar varios _ComputePass_ secuenciales. **Importante:** mantener consistencia para el usuario: el nodo loop sigue siendo uno, pero bajo el cap√≥ podr√≠a engendrar varios passes. El _planner/scheduler_ deber√° detectar construcciones de IR especiales (p.ej., un LOOP_START marcado como ping-pong o multi-res) y en vez de dejarlo dentro de un pass, segmentarlo.
- Por ejemplo, podr√≠a introducirse un nuevo opcode LOOP_END_PASS que indique "termina la iteraci√≥n y requiere un nuevo dispatch con resultados parciales", se√±al para el scheduler de cortar el pass en ese punto.
- Otra opci√≥n es no complicar el IR con eso y manejarlo puramente en execute_compute_tree: detectar nodos loop en el √°rbol Blender antes de IR, y si es de tipo ping-pong o multi-res, ejecutar manualmente dentro de la funci√≥n Python repetidamente. Esto es m√°s procedural y rompe el ideal declarativo del IR, pero simplifica la implementaci√≥n en corto plazo. **Recomendaci√≥n:** Para ping-pong y multi-res, inicialmente implementar la l√≥gica en la capa de ejecuci√≥n Python (m√°s control y posibilidad de debug), e ir migrando a IR/GLSL nativo conforme la necesidad de optimizaci√≥n lo dicte.

En resumen, estas mejoras a los bucles proporcionan construcciones para **iteraci√≥n m√°s poderosa**: desde loops multi-variable hasta patrones de feedback y procesado piramidal. Esto acerca el sistema a Houdini Copernicus, donde existen nodos an√°logos (por ejemplo, _Block Begin/End_ para construir bucles o "for-each" logic) y donde los usuarios pueden configurar loops complejos dentro del flujo de nodos. Nuestro dise√±o busca un balance entre incorporar estas capacidades y mantener claridad de uso. Un **riesgo** a se√±alar es la mayor complejidad en la ejecuci√≥n: ejecutar muchos iteraciones o escalas puede ser costoso; habr√° que proporcionar indicaciones visuales (por ejemplo, limitar _Auto-Execute_ cuando hay loops intensivos, para no recalcular 100 iteraciones en cada cambio trivial). Pero la modularidad del nuevo dise√±o nos permitir√≠a optimizar o paralelizar en GPU en el futuro estas iteraciones pesadas.

## **Soporte Ampliado de Tipos de Datos: Part√≠culas, Point Clouds, Vol√∫menes, Datos Arbitrarios**

Llevar el addon m√°s all√° de im√°genes 2D implica abrirlo a otros dominios de datos. En l√≠nea con la filosof√≠a de Copernicus (que integra COPs con geometr√≠a y vol√∫menes)[\[10\]](https://tokeru.com/cgwiki/HoudiniCops.html#:~:text=%2A%20New%20cops%20flow%20left,back%20to%20the%20viewport%20live), proponemos:

- **Integraci√≥n con nubes de puntos/part√≠culas:** Introducir nodos capaces de **leer y escribir datos de part√≠culas** o point clouds de Blender. Por ejemplo:
- _Nodo Input Particles_: toma un sistema de part√≠culas (o un objeto PointCloud) de la escena y produce un **recurso buffer** con los atributos (posici√≥n, velocidad, etc) de cada part√≠cula. Internamente, esto significar√≠a crear un ResourceDesc de tipo BUFFER y copiar los datos CPU->GPU (posiblemente usando NumPy para empaquetar atributos en un array, luego subi√©ndolo a la textura 1D o SSBO).
- _Nodo Output Particles_: tomar un buffer (tras c√°lculos) y aplicarlo de vuelta a un sistema de part√≠culas o PointCloud. Esto es m√°s complejo pues requiere copiar GPU->CPU. La API gpu probablemente permita leer de un GPUTexture (texture.read() quiz√°s devuelva un array) - habr√≠a que confirmar. En caso afirmativo, se mapear√≠a ese array a las posiciones/atributos de las part√≠culas en Blender.
- Mientras SSBO no est√© accesible, este mecanismo usando texturas 1D funciona, aunque la transferencia CPU/GPU pueda ser un cuello de botella. Un posible _mitigador_ es permitir que ciertos c√°lculos de part√≠culas se hagan totalmente en GPU sin bajar a CPU hasta el final (por ejemplo, encadenar varios nodos de part√≠culas en GPU y solo al final volcar el resultado).
- Cabe se√±alar que Blender 4.x introdujo **Simulation Nodes** en Geometry Nodes para f√≠sica de part√≠culas; nuestro sistema podr√≠a complementarlo ofreciendo c√°lculos arbitrarios en GPU. Sin embargo, hay riesgo de duplicar funcionalidad; debemos enfocarnos en usos donde ComputeNodes brinde aceleraci√≥n o flexibilidad extra (shaders custom, grandes vol√∫menes de part√≠culas, etc.).
- **Soporte de vol√∫menes (grids 3D):** Similar al caso de im√°genes 2D, pero ahora con **Voxel Data**. Podr√≠amos tener:
- _Nodo Volume Input_: toma un objeto Volume de Blender (OpenVDB) y crea una textura 3D (o un buffer 3D) con sus valores. Dado que OpenVDB no es denso, habr√≠a que muestrear a una resoluci√≥n 3D fija. Quiz√° m√°s pr√°ctico es soportar los vol√∫menes densos nativos de Blender (que son como cuadr√≠culas en mantaflow).
- _Nodo Volume Output_: escribe los voxeles procesados de regreso a un objeto Volume o crea uno nuevo.
- Estos nodos implican manejar posiblemente **grandes cantidades de datos**, as√≠ que habr√° que vigilar memoria. A diferencia de im√°genes (donde 4K^2 pixeles ~ 16 millones), un volumen 256^3 ya son ~16 millones de voxels, tratables pero 512^3 son 134 millones (cuidado). Copernicus probablemente maneja vol√∫menes como geometry (VDB) en lugar de texturas completas, aprovechando sparsidad. Nuestro enfoque inicial ser√° para vol√∫menes "peque√±os" o moderados, usando texturas 3D.
- Desde la √≥ptica IR, esto ya queda cubierto con ResourceType.IMAGE + dimension=3D como se discuti√≥. A√±adir√≠amos opcodes si es √∫til (por ej, operaciones espec√≠ficas de vol√∫menes como _voxel slice_, pero puede resolverse con nodos compuestos de b√°sicos).
- **Datos arbitrarios / estructuras personalizadas:** Ser√≠a ideal permitir al usuario manejar datos no previstos, por ejemplo tablas num√©ricas, resultados de simulaciones cient√≠ficas, etc. Esto casi seguro requerir√° **Shader Storage Buffers** (o workaround v√≠a textures) como ya analizamos. Una idea es exponer un nodo tipo _Buffer Input_ que permita al usuario cargar datos desde un archivo CSV/EXR (por ejemplo) o ingresarlos manualmente. Sin embargo, esto sale un poco del √°mbito t√≠pico de un addon nodal para gr√°ficos. Quiz√° m√°s relevante es:
- Soportar **im√°genes multi-capa** o _deep data_: Copernicus tiene noci√≥n de "cables" con m√∫ltiples canales[\[17\]](https://www.sidefx.com/docs/houdini/nodes/cop/index.html#:~:text=Wiring%20COPs%20together%20controls%20the,nodes%20that%20modify%20the%20data)[\[18\]](https://www.sidefx.com/docs/houdini/nodes/cop/index.html#:~:text=Image), por ejemplo un paquete de im√°genes juntas. En nuestro dise√±o podr√≠amos mapearlo a recursos tipo BUFFER donde se concatenan varias capas, o bien a texturas 2D con m√°s componentes (p.ej. RGBA, o usar varias texturas). Esto permitir√≠a manejar datos arbitrarios asociados a cada pixel (m√°s all√° de RGBA). Un caso de uso: almacenar una profundidad Z por pixel junto a color - esto en Copernicus podr√≠a ser un "layer" extra en el cable. Aqu√≠ podr√≠amos implementar nodos _Combine Layers_, _Separate Layers_ que empaqueten/desempaqueten informaci√≥n. Por simplicidad, podemos por ahora limitarnos a RGBA (ya soportado), pero dejar arquitectura preparada para extensiones (p.ej., ImageDesc tiene un campo format donde ya reconocemos RGBA8, RGBA16F, R32F, etc.[\[19\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/codegen/glsl.py#L64-L72); podr√≠amos a√±adir RG32F o similares para otros canales).

En la **arquitectura IR**, la introducci√≥n de nuevos tipos de recurso (BUFFER, VOLUME) se traduce en m√°s entradas en el enum ResourceType y ajustarle la l√≥gica donde corresponda (p.ej., la generaci√≥n de binding en GLSL deber√° distinguir entre imagen y buffer; actualmente solo hace binding de im√°genes[\[20\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/codegen/glsl.py#L56-L65)[\[4\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/codegen/glsl.py#L88-L96)). Probablemente gestionemos buffers sin declararlos en el shader (pues Blender podr√≠a requerir usar shader.buffer(...) en lugar de shader.image(...) para vincularlos - detalle a investigar en API). En caso extremo de no poder declarar SSBO, una idea es usar una \*imagen 1D\* pero accederla v√≠ashader.image("Image_0", bufTexture)\` igual que im√°genes (ser√≠a simplemente otra textura bind, que en GLSL se ve como image2D de width=N, height=1). Esto aprovechar√≠a el mismo mecanismo de binding actual sin cambios dr√°sticos.

**Limitaciones y riesgos:** Soportar estos tipos de datos incrementa la complejidad de sincronizaci√≥n CPU-GPU y el uso de memoria GPU. Copias grandes de ida/vuelta (p.ej. millones de part√≠culas cada frame) pueden anular la ventaja del c√≥mputo GPU. Habr√° que documentar claramente que el mejor rendimiento se logra manteniendo los datos en GPU el mayor tiempo posible (por ejemplo, hacer varias operaciones encadenadas en ComputeNodes y solo al final recuperar el resultado). Otro riesgo es la **complejidad de usuario**: Blender ya tiene Geometry Nodes para puntos/vol√∫menes; habr√° que justificar cu√°ndo usar ComputeNodes (por ejemplo, para escribir un shader personalizado que afecte millones de puntos m√°s r√°pido que Geometry Nodes en CPU, o para operar vol√∫menes con f√≥rmulas complicadas). A nivel t√©cnico, debemos hacer pruebas en distintas GPUs para asegurarnos de que manejar texturas 3D o buffers grandes no cause ca√≠das de rendimiento inesperadas (por ej., algunas GPU podr√≠an no soportar bien _imageLoad_ en texturas muy grandes - quiz√°s debamos implementar particionado/tiled processing en el futuro, aunque es avanzado).

## **Dise√±o Modular y Nodos de Scripting Personalizado (GLSL in-node)**

La modularidad del sistema es crucial para mantenerlo extensible y mantenible. El MVP ya separa varias capas: definici√≥n de nodos Blender, construcci√≥n de IR (antes centralizado en una sola funci√≥n, ahora migrando a _handlers_ modulares[\[21\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract/registry.py#L10-L18)), generaci√≥n de c√≥digo GLSL mediante _emitters_ registrables[\[22\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/codegen/glsl.py#L168-L176) y ejecuci√≥n mediante gestores de recursos y shaders. Identificamos varias mejoras de dise√±o:

- **Refactor de extracci√≥n IR y registro de handlers:** La existencia de graph_extract_old.py indica que el MVP inici√≥ con una funci√≥n monol√≠tica para traducir nodos a IR[\[23\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L17-L25)[\[24\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L35-L44). Ahora se pretende usar un registro por tipo de nodo (HANDLER_REGISTRY mapeando bl_idname a funci√≥n)[\[25\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract/registry.py#L11-L19). Aseguraremos que cada tipo de nodo tenga su handler bien definido, reduciendo _hardcodes_. Por ejemplo, en el MVP la extracci√≥n del nodo Output no aparec√≠a en el registro, sino que se manejaba al final ad-hoc[\[26\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L876-L885)[\[27\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L905-L914). Proponemos convertir eso tambi√©n en un handler (p.ej. handle_output_node) que encapsule la l√≥gica de crear el ImageDesc de destino (si no viene de otro nodo) y generar la operaci√≥n de escritura (IMAGE_STORE). As√≠ evitamos c√≥digo especial disperso. Igualmente, la l√≥gica de bucles puede modularizarse: en lugar de anidar recursivamente process_node como ahora, un handler handle_repeat_output deber√≠a construir las ops IR de loop correspondientes[\[28\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L8-L11), mejorando legibilidad. Este enfoque **facilita a√±adir nuevos nodos**: solo se escribe una funci√≥n de manejo y se registra, sin tocar la m√°quina de extracci√≥n central.
- **Sistema de generaci√≥n GLSL extensible:** De modo an√°logo, la generaci√≥n de c√≥digo usa emisores registrables (funciones lambda que construyen c√≥digo por opcode)[\[22\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/codegen/glsl.py#L168-L176). Hoy existen _emitters_ para la mayor√≠a de opcodes (math, vector, etc.). Hay que asegurarse de que agregar un nuevo opcode sea simple: actualizar el enum OpCode y registrar su emitter. Un potencial problema es que algunos nodos complejos generan _secuencia_ de ops (no una sola). Por ejemplo, _Separate Color_ produce varios outputs; su emitter actualmente necesita declarar m√∫ltiples variables de salida manualmente en GLSL (por eso est√° en self_declaring_ops para tratamiento especial)[\[29\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/codegen/glsl.py#L148-L156). Podr√≠amos mejorar esto permitiendo que un emitter opcionalmente devuelva no solo c√≥digo sino tambi√©n instrucciones de declaraci√≥n extra. Otra alternativa es **introducir plantillas** para conjuntos de operaciones frecuentes: p.ej., muchas operaciones matem√°ticas componente a componente se parecen. Podr√≠amos factorizar un emitter gen√©rico para binarios (a op b) que reciba el s√≠mbolo operatorio. A√∫n as√≠, dado que la lista de opcodes es finita, mantener los emitter expl√≠citos es aceptable y claro.
- **Nodo de scripting GLSL in-node:** Esta es una funcionalidad potente para usuarios avanzados: un nodo donde puedan **escribir c√≥digo GLSL personalizado** que se inserte en el shader. Equivalente a un "Script Node" (similar al nodo OSL Script en Cycles, pero aqu√≠ en GLSL para Eevee/Compute). Para implementarlo:
- Crearemos un nuevo nodo Blender, e.g. ComputeNodeScript con un **propiedad de texto multilinea** (o un enlace a un Text datablock de Blender para edici√≥n m√°s c√≥moda). En el dibujo del nodo, mostraremos un peque√±o editor o al menos el nombre del script vinculado.
- En la extracci√≥n IR, este nodo se manejar√° de forma especial: deber√° **generar IR din√°mico**. Podemos optar por introducir un opcode gen√©rico tipo OpCode.CUSTOM para representarlo, con atributos que incluyan el c√≥digo fuente y metadatos de entradas/salidas. Sin embargo, quiz√°s no valga la pena pasarlo por IR detallado; podr√≠amos simplemente encapsularlo hasta la generaci√≥n GLSL.
- Propuesta: El handler del Script Node crear√° _Values_ IR para cada salida del nodo (como placeholders), pero no agregar√° ops regulares. Luego, en la fase de generaci√≥n GLSL, detectaremos este nodo y **insertaremos su c√≥digo fuente**. ¬øC√≥mo? Dos maneras:
  - **Inline en main():** Tomar el c√≥digo escrito e inyectarlo en el cuerpo del shader, antes de usar sus resultados. Por ejemplo, si el usuario escribe algo como vec3 col = inColor \* vec3(2.0); outColor = vec4(col, 1.0);, podr√≠amos insertarlo tal cual con las variables correspondientes ya definidas.
  - **Como funci√≥n auxiliar:** En vez de inline, podr√≠amos envolverlo en void nodeFunc(vecX input1, ..., out vecY out1, ...) { ... } y llamarla desde main. Esto ser√≠a m√°s limpio si el c√≥digo es extenso y reutilizable. Pero para simplicidad inicial, inline est√° bien.
- Debemos proveer al c√≥digo del usuario los **nombres de variables de entrada**. Proponemos una convenci√≥n: por ejemplo, el Script Node con N entradas podr√≠a exponerlas como in0, in1, ..., inN en su c√≥digo, y las salidas como out0, out1, .... El addon, al generar, reemplazar√° esos identificadores con los verdaderos nombres de variables SSA en GLSL. Por ejemplo, si in0 corresponde a un Value %5 (v5 en GLSL) y out0 corresponde a %6, podr√≠amos hacer: vec3 v6 = /\*user code with v5\*/;. Alternativamente, podr√≠amos pre-generar l√≠neas antes: vec3 in0 = v5; luego el c√≥digo, luego asignar v6 = out0;. Cualquier m√©todo requiere _parsear_ ligeramente el texto del usuario o especificar claramente c√≥mo debe formatearlo. Para facilitar, podemos pedir que el usuario devuelva directamente el resultado, p. ej.: _"outColor = ...;"_. En cuyo caso, nuestro engine puede simplemente injertar su c√≥digo dentro del main() y confiar en que asigna a variables nombradas outColor que nosotros habremos declarado.
- **Seguridad y validaci√≥n:** Una preocupaci√≥n es que un error en el c√≥digo del usuario generar√° un fallo de compilaci√≥n del shader. Debemos capturar el log de compilaci√≥n (Blender _GPUShader_ suele proveer el log de compilaci√≥n si falla) y reportarlo al usuario. Podr√≠amos utilizar shader.validate() si existe, o envolver la creaci√≥n con try/except y extraer el mensaje. Luego, ese mensaje se podr√≠a mostrar en la interfaz, quiz√°s marcando el nodo en rojo y poniendo el error en su label.
- **Limitaciones del script node:** Para mantenerlo manejable, inicialmente restringiremos que solo opere con tipos escalares o vectores "por pixel". Es decir, no deber√° por s√≠ mismo llamar a _imageLoad_ ni realizar accesos a recursos externos - esas operaciones seguir√°n hechas v√≠a nodos espec√≠ficos (Input Image, Sample, etc.) cuyos resultados puede tomar como inN. Esto porque si permitimos acceso arbitrario a im√°genes dentro del c√≥digo, saltar√≠amos el IR y planificador, pudiendo introducir hazards no controlados. Si un usuario experto realmente quiere hacer algo muy custom (por ejemplo, un filtro que lee vecinos de un pixel), _podr√° hacerlo_ combinando: usar un Position node para obtener coord, luego dentro del script usar funciones GLSL con esa coord para samplear una textura. De hecho, necesitamos exponer quiz√°s alg√∫n mecanismo para acceder a texturas dentro del script. Una opci√≥n sencilla es permitir que _entradas de imagen_ en el script node generen directamente un uniform sampler2D accesible. Podr√≠amos mapear un socket de tipo ComputeSocketImage en el Script Node a un uniform readonly image2D Image_N. Sin embargo, eso es complejo porque implicar√≠a que el usuario escriba por ejemplo vec4 px = imageLoad(Image_0, ivec2(x,y)); dentro de su c√≥digo. Esto puede hacerse si documentamos que Image_0 estar√° disponible (tal como lo hacemos con shader.image("Image_0", tex) en la API[\[30\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py#L142-L150)). Por ahora, quiz√° limitamos script node a operaciones matem√°ticas sobre sus inputs num√©ricos; m√°s adelante podr√≠amos permitir que reciba im√°genes y use sus valores mediante alguna API (tal vez inyectando tambi√©n el c√≥digo de muestreo).

En definitiva, el **nodo de script** agrega enorme flexibilidad: los usuarios podr√°n implementar operaciones no previstas (ej: un filtro art√≠stico, una funci√≥n matem√°tica especial) escribiendo unas l√≠neas de GLSL en lugar de esperar a que el addon las incorpore. Esto acelera la adopci√≥n por _power users_. El principal riesgo es la **usabilidad**: no todos los artistas saben GLSL, y exponerlo podr√≠a ser intimidante. Sin embargo, al tratarse de un addon especializado, es aceptable que sea una caracter√≠stica orientada a TDs o desarrolladores t√©cnicos. Otro riesgo menor es que cambios en la API GPU de Blender (por ejemplo, con la transici√≥n a Vulkan y uso de SPIR-V) puedan requerir ajustar la sintaxis esperada en estos scripts. A corto plazo, mantendremos GLSL como lenguaje (que Blender seguir√° aceptando y compilando detr√°s de escena[\[31\]](https://devtalk.blender.org/t/python-shadercreateinfo-missing-in-blender-4-5-what-s-the-plan/42007#:~:text=plan%3F%20devtalk,don%27t%20work%20under%20Vulkan)) y monitorearemos cualquier deprecaci√≥n.

- **Puntos de extensibilidad y modularidad adicional:** Con la infraestructura de handlers y emitters, agregar un **nuevo nodo nativo** (no script) ser√° bastante directo. Podemos documentar un procedimiento para ello, e incluso pensar en permitir **plugins externos** que registren nodos en ComputeNodes. Por ejemplo, si un desarrollador quiere agregar un conjunto de nodos para cierto efecto (AI denoising, etc.), idealmente podr√≠a sin modificar el core, registrar m√°s NodeItems y asociar sus funciones IR/GLSL. Para soportar eso, conviene que el registro de handlers y emitters est√© accesible p√∫blicamente (p.ej. exponer compute_nodes.graph_extract.get_handler y permitir hacer HANDLER_REGISTRY\["MyNode"\] = my_handler). Similar con emitters. Debemos, no obstante, cuidar que no se rompa encapsulamiento: quiz√°s ofrecer una API oficial como compute_nodes.register_custom_node(node_class, handler_func, emitter_func). Esto realmente convertir√≠a el addon en una **plataforma extensible** dentro de Blender.
- **Soluci√≥n de inconsistencias de dise√±o actuales:** Aprovecharemos la revisi√≥n modular para corregir algunos problemas detectados:
- El **nodo Output** actualmente tiene propiedades width, height, format pero en la extracci√≥n original no se usaban si no hab√≠a imagen de destino conectada (no se creaba la ImageDesc autom√°ticamente)[\[32\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L880-L889)[\[27\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L905-L914). Corregiremos esto haciendo que si ComputeNodeOutput.image (socket de entrada) no est√° ligado a nada, el handler cree un ImageDesc nuevo con el nombre/size/format del nodo Output. De ese modo el output siempre tiene un recurso v√°lido. Este cambio eliminar√° la necesidad de tener un nodo "ImageWrite" separado para simplemente definir la imagen final - podr√≠amos incluso deprecar ComputeNodeImageWrite y quedarnos solo con Output manejando la creaci√≥n (o redefinir ImageWrite como un alias de Output con menos opciones).
- **Dynamic socket update issues:** Algunos nodos (Switch, Mix, Separate Color, Combine Color, Map Range) cambian sus sockets seg√∫n propiedades (tipo de dato, modo de color, etc.)[\[33\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/control_flow.py#L30-L38)[\[34\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/converter.py#L53-L61)[\[35\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/converter.py#L149-L157). Debemos verificar que esos cambios se reflejan correctamente en el IR. Actualmente, la extracci√≥n de nodos toma sockets por nombre; si un socket est√° oculto (socket.hide=True) pero sigue existiendo, igual se considerar√≠a. En el handler habr√≠a que respetar qu√© entradas est√°n activas. Posible mejora: hacer que los handlers usen los mismos criterios que el UI (p.ej., handler de Mix consultar√° la propiedad .data_type del nodo y solo procesar√° los sockets relevantes). Esto previene p.ej. que un Mix en modo Vector intente sumar floats porque qued√≥ un socket residual oculto.
- **Operaciones l√≥gicas y comparaciones:** El IR define opcodes como AND, OR, EQ, LT, etc.[\[36\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/ir/ops.py#L66-L74) pero en el MVP no hay nodos de l√≥gica dedicados (aunque un Compare podr√≠a mapear a EQ/GT...). Decidiremos si agregar nodos l√≥gicos (podr√≠a ser √∫til en conjunci√≥n con Switch) o si dejarlo para el usuario v√≠a Script node. En todo caso, limpiar lo que est√© definido pero no usado para mantener consistencia.
- **Gesti√≥n de formatos num√©ricos:** Hoy casi todo es float32 en GPU (salvo se mencionan UINT/INT en DataType[\[37\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/ir/types.py#L4-L13)). Si quisi√©ramos soportar _integer images_ (RGBA8I/UI), la IR y codegen ya prev√© algunos formatos[\[38\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/codegen/glsl.py#L70-L73). Podemos exponerlo en la UI (por ejemplo, permitir al usuario elegir formato entero en Output). Pero esto introduce la necesidad de manejar tipos en operaciones (no todas las ops admiten ints en GLSL sin conversi√≥n). Por ahora, podr√≠amos documentar que el pipeline trabaja principalmente en float (como ocurre en Compositor tradicional), y soportar INT en casos puntuales. Modularmente, eso significa que en IR DataType.INT existe pero debemos usarlo con cuidado. Un _target_ futuro es permitir im√°genes de m√°scara (8-bit) y datos en entero sin perder precisi√≥n, pero se sale un poco del foco inmediato.

En s√≠ntesis, este redise√±o modular hace al sistema **m√°s f√°cil de expandir y personalizar**. Los nodos de scripting brindan un _escape hatch_ para casos especiales, mientras que los registros de handlers/emitters aseguran que internamente las nuevas funciones no introduzcan espagueti. Un riesgo de tanta modularidad es la sobrecarga en rendimiento (llamadas Python extra, etc.), pero en general la mayor parte del trabajo sucede en GPU; la extracci√≥n IR/compilaci√≥n shader ocurre al ejecutar el √°rbol (no por pixel), por lo que unos pocos niveles de indirecci√≥n Python no ser√°n problema. Mantendremos pruebas unitarias (como ya hay un test_runtime.py b√°sico[\[39\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py#L85-L93)[\[40\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py#L117-L125)) para corroborar que la cach√© de shaders, creaci√≥n de texturas, etc., siguen funcionando con estos cambios, y ampliaremos esos tests a nuevos nodos.

## **Dominios y Resoluci√≥n: Comparativa con Houdini Copernicus, Debilidades y Mejora de Dise√±o**

En sistemas de composici√≥n avanzados (Nuke, Houdini COPs/Copernicus), el manejo de la **resoluci√≥n de im√°genes** y sus **dominios** es fundamental. Actualmente, ComputeNodes sigue un enfoque simplificado: **una √∫nica resoluci√≥n global por nodetree**. Identifiquemos las diferencias clave con Copernicus y propongamos mejoras:

- **Resoluci√≥n global fija vs. resoluciones por nodo:** En el MVP, al ejecutar el gr√°fico se determina un tama√±o de imagen "contexto" - generalmente tomado del nodo Output o de la primera imagen de escritura encontrada[\[1\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L46-L55). Todo el _compute shader_ corre en ese tama√±o (usando gl_GlobalInvocationID.x/y hasta width/height) y se asume que las operaciones se aplican a ese lienzo[\[41\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L920-L928). Esto significa que **todas las im√°genes involucradas se consideran de ese tama√±o**, lo cual es una suposici√≥n muy fuerte. Si un Input Image tiene distinta resoluci√≥n, actualmente no hay l√≥gica para ajustar eso: probablemente ser√≠a muestreada fuera de rango o habr√≠a que confiar en que el usuario escal√≥ la imagen externamente. En Copernicus, en cambio, **cada nodo puede operar a su resoluci√≥n nativa** (cada COP es como una imagen/volumen con su propia transform/voxel size). De hecho, Copernicus representa im√°genes como _geometr√≠a 2D_ y las combina en el espacio 3D - es decir, no fuerza a que todas tengan igual tama√±o, sino que realiza transformaciones impl√≠citas o expl√≠citas al componer[\[10\]](https://tokeru.com/cgwiki/HoudiniCops.html#:~:text=%2A%20New%20cops%20flow%20left,back%20to%20the%20viewport%20live). Esta flexibilidad permite, por ejemplo, componer una imagen HD sobre un lienzo 4K offseteada, o procesar texturas peque√±as sin malgastar fillrate.
- **Debilidades del enfoque actual:** La falta de manejo de resoluciones m√∫ltiples se traduce en:
- **Imposibilidad de mezcla de im√°genes de distinto tama√±o**: no hay nodos para reescalar ni offsets, as√≠ que el usuario est√° limitado a usar im√°genes ya del mismo tama√±o.
- **Falta de nodos de transform**: no se contempl√≥ nodos para trasladar, rotar o escalar im√°genes (comunes en compositing). Indirectamente, sin sistema de coordenadas flexible por imagen, estos nodos no existen.
- **No soporte de ROI (Regions of Interest)**: En compo es √∫til procesar solo una ventana de la imagen; aqu√≠ siempre se procesa la totalidad fija.
- **Cascada de resoluciones manual imposible**: Como se discuti√≥, no se puede generar pir√°mides salvo cambiando la resoluci√≥n global entre ejecuciones.
- **Desperdicio de c√≥mputo**: Si una cadena de nodos produce un resultado final peque√±o o un mask de baja res, igual estamos calculando a la m√°xima res global en cada paso, sobrecargando la GPU.
- **Propuesta de manejo robusto de dominio/resoluci√≥n:** Tomando inspiraci√≥n de Houdini:
- Introducir el concepto de **Dominio de Imagen** en el nodetree. Cada recurso de tipo imagen en IR ya lleva un size. En lugar de homogenizarlos inmediatamente al extraer el gr√°fico, conservaremos esos tama√±os individuales en la IR y tomaremos decisiones de compatibilidad durante el planificado o la ejecuci√≥n. Es decir, permitiremos que en un mismo Graph IR coexistan ImageDesc de distintos tama√±os.
- **Reglas de combinaci√≥n**: Cuando un nodo toma dos im√°genes de distinto tama√±o, ¬øqu√© hacer? Podemos definir comportamiento por defecto y permitir anularlo:
  - Por defecto: Adoptar el dominio del **√°rbol principal** (p. ej., del Output final) y _re-muestrear impl√≠citamente_ las im√°genes m√°s peque√±as o m√°s grandes a ese tama√±o cuando se usen. Esto es simple pero oculta procesos. Copernicus probablemente no reescala impl√≠citamente sin avisar; usualmente hay nodos para eso. Quiz√° mejor opci√≥n:
  - Requerir un nodo expl√≠cito de **Reformat/Resize** para cambiar resoluciones. Es decir, si el usuario conecta una imagen 512x512 a otra de 1024x1024 en un Mix, podr√≠amos: o bien automatizar (suponer que la 512 se estira centrada), o marcar un aviso de _mismatch_ recomendando insertar un nodo Resize. Blender Compositor tradicional opta por el ajuste impl√≠cito (toma por defecto la resoluci√≥n del primer input del nodo compositor y reescala el segundo).
  - Para mayor control profesional, inclinamos por la v√≠a expl√≠cita: el usuario debe insertar un nodo _Resize_ o _Set Domain_ si quiere cambiar. Sin embargo, podr√≠amos seguir la convenci√≥n de Blender Compositor para familiaridad: e.g., en un Mix Node, considerar la imagen de mayor resoluci√≥n como base y reescalar la menor (usando nearest or linear). Esto se podr√≠a implementar en el _handler_ del Mix: si detecta inputs de diferente tama√±o, generar en IR una secuencia: tmp = resize(input_small, size_of_large) seguido del op mezcla. O m√°s sencillo, en el shader del Mix samplear la chica con coordenadas normalizadas - esto se logra si se conoce ratio de tama√±os.
  - **Recomendaci√≥n de compromiso:** Implementar comportamiento por defecto (evitar bloquear al usuario): usar la resoluci√≥n mayor entre inputs para los c√°lculos, reescalando internamente la otra. Y adem√°s, proveer un nodo _Resize_ para casos en que el usuario quiera un control espec√≠fico (interpolaci√≥n linear vs nearest, o elegir una resoluci√≥n arbitraria).
- **Nodos de transformaci√≥n y dominio:** A√±adir nodos como _Translate_, _Scale (UV)_, _Rotate_ que modifiquen la posici√≥n de una imagen dentro de otra. En IR, esto no cambia la resoluci√≥n de la imagen, sino c√≥mo se calculan sus coordenadas de muestreo. Podemos implementar, por ejemplo, un nodo Translate que toma una imagen y una offset (dx, dy) y produce una nueva imagen del mismo tama√±o que la de contexto, cuyo shader simplemente toma cada coordenada (x,y) y la muestrea de la imagen entrada en (x-dx, y-dy) (aplicando borde negro si sale fuera). Esto, junto con _Resize_, cubre la funcionalidad de mover im√°genes de distintos tama√±os por un lienzo com√∫n.
- **Multiples salidas finales:** Blender Compositor permite tener varias salidas (Composite, Viewer, File Output). Copernicus permite varios output COPs. En ComputeNodes podr√≠amos permitir **varios nodos Output** en un mismo √°rbol, cada uno con su propia resoluci√≥n/imagen destino. El IR Graph ya soporta m√∫ltiples recursos de salida. Actualmente el extractor solo busca uno[\[24\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L35-L44), pero podemos adaptarlo para recoger todos los ComputeNodeOutput presentes. Cada output generar√≠a una correspondiente IMAGE_STORE en IR hacia su recurso. El _scheduler/execute_ tendr√≠a que manejar quiz√°s lanzar distintos shaders si sus resoluciones difieren o si necesitan separarse por dependencia (de hecho, _schedule_passes_ ya agrupar√° las ops; es posible que cada output termine en un pass separado si no est√°n enlazados entre s√≠). Esto permitir√≠a, por ejemplo, calcular a la vez una salida full HD y una miniatura en un solo nodetree.
- **Planificador consciente de resoluci√≥n:** Extenderemos la funci√≥n de _hazard detection_ para incluir **cambios de resoluci√≥n** como criterio de divisi√≥n de passes. Ya notamos que en schedule_passes hay un TODO sobre "diferentes requerimientos de dispatch"[\[7\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/planner/scheduler.py#L20-L28). Implementaremos all√≠ que si una op va a escribir a un recurso con tama√±o distinto al actual contexto, se haga un corte de pass antes de esa op. En otras palabras, agruparemos en un pass todas las ops que comparten el mismo dominio, y si viene una op para otro dominio, empezamos un nuevo pass (y potencialmente insertamos una op de reformat impl√≠cito si arrastra datos).
  - Ejemplo: un tree genera primero una imagen en mitad de resoluci√≥n, luego la usa para componer sobre full res. El planner podr√≠a crear Pass1 (hasta generar la imagen half-res), luego Pass2 (que lee esa imagen y lee otras a full res, componiendo en full res). Entre Pass1 y Pass2, se detecta que la imagen half-res es le√≠da en un contexto full-res; el scheduler puede insertar una **etapa de upscale** (esto podr√≠a ser autom√°tico o dejado al shader de Pass2 como muestreo escalado). Quiz√° m√°s limpio: hacer que Pass2 directamente muestree con coords normalizados la textura half (no necesita upscaling expl√≠cito, el shader lo maneja).
- **Actualizaci√≥n de ejecuci√≥n:** El ComputeExecutor.execute_graph hoy determina un solo context_width, context_height y lanza el dispatch[\[1\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L46-L55)[\[42\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L64-L71). Con passes de distinta resoluci√≥n, tendremos que recalcular el tama√±o antes de cada dispatch. Nuestra implementaci√≥n del _scheduler_ puede a√±adir esa info a cada ComputePass (un pass podr√≠a guardar pass_width, pass_height). De hecho, podr√≠amos llenar esos campos al crear los passes: por ejemplo, al cortar passes por hazard o res, setear el tama√±o al de la mayor _write_ en ese pass (o a alguna referencia). En ejecuci√≥n, antes de hacer shader.bind() y compute.dispatch, dimensionar el dispatch con esos valores. Las texturas internas tambi√©n deben prepararse con esas dimensiones (p.ej., si Output pide 1024x1024 y otra rama tiene 512x512, debemos haber creado ambos en TextureManager).
- **Persistencia de recursos entre passes:** Cuando se separen passes por resoluciones, asegurarse de que un recurso de menor res producido en Pass1 sigue accesible en Pass2. En el MVP, \_texture_mgr guarda texturas internas en un diccionario (\_internal_textures) por nombre[\[43\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py#L80-L88)[\[44\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py#L94-L101). Mientras usemos el mismo name para la ImageDesc, la textura se conservar√°. Al cambiar de pass, al hacer shader.image("Image_#", tex) se usar√° la misma GPUTexture previamente calculada. Esto significa que no hay que copiar manualmente nada; solo hay que garantizar que **no liberamos ni recreamos la textura small de nuevo**. El TextureManager actual tiene ensure_internal_texture(name, desc) que crea si no existe[\[44\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py#L94-L101); si ya existe no la duplica. Cuando produzcamos la half-res, llamaremos con su nombre una vez, quedar√° almacenada, y luego en el pass siguiente la pediremos como input. Esto ya funciona en MVP para casos simples de multi-pass (e.g., si hubiera un ImageWrite intermedio). Nos aseguraremos de usar identificadores √∫nicos (quiz√° basado en nodo nombre o ID) para cada recurso intermedio para no colisi√≥n.

Con estas mejoras, **ComputeNodes soportar√° m√∫ltiples resoluciones de forma controlada**, reduciendo la brecha con herramientas profesionales. En **Houdini Copernicus**, los usuarios pueden tener copias de im√°genes de distintos tama√±os conviviendo y COPs que operan como "vol√∫menes 2D" que integran con geometr√≠a. Nuestro sistema no llega al punto de integrar con 3D viewport (Copernicus permite previsualizar composiciones en el contexto 3D)[\[45\]](https://www.sidefx.com/docs/houdini/nodes/cop/index.html#:~:text=COP%20nodes%20provide%20real,manipulation%20within%20a%203D%20space), pero en cuanto a l√≥gica de tama√±os estaremos m√°s cerca: permitiendo diferentes resoluciones, transformaciones 2D, y nodos de reformat. Un posible riesgo es **mayor complejidad para el usuario novel**, pues tendr√° que entender cu√°ndo necesita un Resize o por qu√© una imagen se estira. Mitigaremos esto con comportamientos por defecto sensatos (reescalar al mayor tama√±o, similar al compositor de Blender). Tambi√©n se recomienda proveer buenos _tooltips_ y documentaci√≥n en la wiki del addon sobre manejo de resoluciones. En rendimiento, ofrecer dominios menores puede **mejorar performance** (p. ej. procesar un blur en 1/2 resol. por loop, luego upscaling, ahorra muchos shader invocations). No obstante, la fragmentaci√≥n en m√∫ltiples passes a√±ade overhead de lanzar varios shaders; habr√≠a que medir, pero normalmente merece la pena si se reduce dram√°ticamente el c√≥mputo por pass.

## **Experiencia de Usuario (UX) y Coherencia con Sistemas de Nodos de Blender**

Para lograr adopci√≥n, ComputeNodes debe sentirse como "parte natural" del ecosistema Blender, encajando con Shader Nodes, Geometry Nodes y Compositor en t√©rminos de interacci√≥n y apariencia. Abordaremos varios aspectos UX:

- **Interfaz de nodos consistente:** Usaremos convenciones est√°ndar de Blender:
- Mantener √≠conos y colores de nodos acordes a su funci√≥n (ya se usan √≠conos de Blender e.g. IMAGE_DATA, TEXTURE, OUTPUT, etc. en bl_icon[\[46\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/input.py#L6-L14)[\[47\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/output.py#L14-L22)). Si a√±adimos nodos (Particles, Volume), buscaremos iconos adecuados (por ej. usar icono de punto para point cloud, etc.).
- Nombrado de nodos y propiedades en **idioma Blender**: por ejemplo, "Mix" en vez de "Lerp", "Value" en vez de "Scalar", etc., tal como ya est√° (ComputeNodeMath usa nombres coincidentes con el nodo Math est√°ndar de Blender[\[48\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/math.py#L10-L19)). Esto reduce curva de aprendizaje al reutilizar conocimiento del usuario.
- Organizaci√≥n en categor√≠as del men√∫ Add Node similar a otros editores: ya se tiene Input, Texture, Math, etc.[\[49\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/categories.py#L10-L19). Agregaremos nuevas categor√≠as si procede (quiz√° "Particles" o "Volumes" para esos nodos), manteniendo la estructura clara.
- Compatibilidad con **Frames y Reroutes**: Blender permite agrupar nodos en marcos y puntos de reroute. Nuestro nodetree deber√≠a soportarlos sin problema (heredados de NodeTree base). Verificaremos que arrastrar noodles, duplicar nodos (Shift+D), buscar nodos (men√∫ Add > Search) funcionen correctamente dentro de nuestro espacio.
- **Nodo Group y encapsulaci√≥n:** Una gran ventaja en Blender es la capacidad de hacer **Group Nodes** (sub-√°rboles reutilizables con interfaz simplificada). Deber√≠amos soportar que usuarios creen grupos dentro de ComputeNodeTree. Si Blender no lo activa por defecto para custom nodetrees, buscaremos c√≥mo hacerlo (posiblemente setting \`bl_options = {'NODE_GROUP'} or similar en NodeTree class). Esto permite encapsular l√≥gica compleja (por ej. un bucle multi-step) dentro de un nodo reusado. Tambi√©n es necesario si se quiere, en un futuro, crear **node presets** o compartir nodetrees.
- Notar: Si grupos funcionan, habr√≠a que exponer entradas/salidas de grupo, etc., lo cual Blender maneja con Group Input/Output nodes. Debemos registrar equivalentes para ComputeNodeTree (similar a Geometry Nodes). Esto quiz√° requiera definir ComputeNodeGroupInput y ComputeNodeGroupOutput que hereden de Node, poll en ComputeNodeTree, y se usan internamente. No es trivial pero vale la pena.
- Un posible riesgo es la compatibilidad con nuestra IR: al entrar a un grupo, hoy no existe concepto en IR, pero Blender "aplana" el group al evaluarlo (al menos en compositor, internamente conecta nodos). Dado que nuestro extraction recorre tree.nodes, esperemos que Blender expanda los grupos en node_tree.nodes accesibles directamente; si no, tendremos que recursivamente soportar nodetrees anidados. Esto es un tema para investigar; de no poder en esta versi√≥n, podr√≠amos posponer grupos manteniendo todo en un nivel.
- **Backdrops o previews:** En el Compositor de Blender existe el _backdrop_ (fondo con la imagen resultante de un nodo Viewer). Ser√≠a muy √∫til para flujos de im√°genes ver resultados intermedios sin salir del editor de nodos. Evaluaremos si es posible habilitar backdrop en nuestro editor:
- Blender activa backdrop si space_data.show_backdrop y con un node tipo Viewer. Podr√≠amos introducir un ComputeNodeViewer que simplemente toma una imagen y la muestra, similar al Viewer del compositor. Sin embargo, en compositor el viewer dibuja en el UV/Image Editor; en Node Editor solo se ve como fondo. Quiz√° reutilizable.
- Si es demasiado esfuerzo, otra v√≠a: facilitar al usuario enviar resultados a el editor de Imagen. Por ejemplo, permitiendo que el nodo Output cree o use un Image datablock, que el usuario puede abrir en UV/Image Editor. Esto ya sucede: Output tiene output_name y crea la imagen en bpy.data.images. Podemos mejorar la _usabilidad_ actual: en el panel lateral "Compute Runtime" podemos a√±adir un bot√≥n "Open Output in Image Editor" que abra la imagen de salida en una ventana de UV/Image. O incluso, autom√°ticamente tras ejecutar, buscar si hay un √°rea de UV Editor y refrescarla.
- Para previsualizar intermedios, podr√≠amos sugerir al usuario usar m√∫ltiples Output nodos marcados como _Preview_ y tener varias im√°genes (aunque esto no es interactivo como un backdrop). Alternativamente, implementar un nodo Viewer especial que al ejecutarse copie su input a Viewer Image (un datablock global) y luego actualice la ventana de image editor (similar a compositor). Este ser√≠a un _nice-to-have_ para la UX.
- **Controles de ejecuci√≥n y feedback:** Ya se tiene un panel N con bot√≥n "Execute" y toggle auto_execute[\[50\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L120-L128). Es importante a√±adir quiz√°s alguna **indicaci√≥n de estado** cuando el grafo est√° ejecut√°ndose, sobre todo si tardar√°. Blender no proporciona por defecto barra de progreso para compute shaders, pero podemos:
- Deshabilitar temporalmente el bot√≥n durante la ejecuci√≥n (ya que es r√°pida normalmente, no cr√≠tico).
- M√°s √∫til: si se lanza una tarea muy pesada (imaginemos 8K imagen con 100 iteraciones), quiz√°s convenga integrarse con el mecanismo de bpy.app.handlers para no bloquear la UI. Tal vez lanzar en un modal timer o en un thread (aunque Blender y threads es delicado). De momento, supondremos que la mayor√≠a de operaciones son r√°pidos (ms a pocos sec). Para futuros, se puede explorar correr en un background thread y mostrar una animaci√≥n de progreso en panel (dif√≠cil sin bloquear GL context, por ahora omitible).
- **Soporte de Undo/Redo:** Revisaremos que la edici√≥n en nuestro NodeTree entra al historial de _Undo_ de Blender correctamente (generalmente s√≠, ya que agregar/remover nodos, conectar sockets son ops registradas). Sin embargo, la ejecuci√≥n del grafo no debe romper el deshacer (crear una imagen output modifica bpy.data, lo cual entra en undo stack - podr√≠amos marcar la imagen creada como no-undo?). Por consistencia, probablemente convenga que crear la imagen de salida _s√≠_ sea registrable para undo (as√≠ si el usuario se arrepiente de haber ejecutado, borra la imagen).
- **Mensajes de error y depuraci√≥n:** Cuando algo falla (p.ej. shader no compila, o el usuario conecta un tipo incorrecto que nuestro sistema no pudo inferir), debemos comunicarlo claramente:
- Usar node.error_message: Blender 4.0 introdujo la propiedad Node.message para mostrar errores en nodos. Podemos aprovechar esto: si en execute_compute_tree capturamos una excepci√≥n, podr√≠amos encontrar qu√© nodo la caus√≥ (dif√≠cil si error es en shader compile). Al menos podr√≠amos colocar un mensaje gen√©rico en el panel o en un nodo especial (como Output).
- Un paso √∫til es loguear en la consola de Blender todos los _tracebacks_[\[51\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L76-L80) (ya se hace) pero eso no ayuda al usuario t√≠pico. Quiz√° en la UI, si ocurre fallo, podr√≠amos desplegar un pop-up self.report({'ERROR'}, "...") que Blender muestra en la barra de estado.
- Para depuraci√≥n avanzada (desarrollador), podr√≠amos implementar en el panel un toggle "Debug" que, al ejecutar, imprima el GLSL generado o lo guarde en un texto Blender. De hecho, en execute_compute_tree ya se guarda p.display_source = p.source[\[52\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L38-L46), podr√≠amos exponer eso. Tener el shader code visible ayuda a diagnosticar problemas de precisi√≥n, etc.
- **Documentaci√≥n y ejemplos:** Para fomentar coherencia con expectativas de usuarios de nodos, a√±adiremos ejemplos de uso en la documentaci√≥n (por ejemplo, "C√≥mo crear un blur progresivo usando loop ping-pong", "C√≥mo procesar part√≠culas con ComputeNodes"), analog√°ndolos con equivalentes en Geometry Nodes o Compositor para que ubiquen mentalmente el flujo. Idealmente, incluiremos esas demos dentro del addon (quiz√° un blend de ejemplo, o nodetrees prearmados).
- **Atajos y operabilidad:** Alinearemos atajos con Blender: por ejemplo _Mute node_ (M key) deber√≠a funcionar. Mute es soportado por Node.mute en Cycles/Compositor. En nuestros nodos, podemos respetarlo: Blender autom√°ticamente no ejecuta nodos muteados y pasa su input directo a output. No obstante, habr√≠a que confirmar que ComputeNode.mute exista; si no, implementar un poll en extract_graph que ignore nodos con .mute. Esto facilita depurar un graph complejo (el usuario puede mutear temporalmente un nodo para ver efecto). Marcaremos los nodos muteados visualmente en interfaz (Blender lo hace).
- **Consistencia con Geometry Nodes en "Simulaci√≥n":** Blender Geometry Nodes 4.0 introdujo _Simulation Zones_ (bucle para frame-by-frame). Aunque es un contexto distinto, los usuarios pueden esperar que nuestros Repeat Zones se comporten parecido. Podemos copiar ciertos UI cues: por ejemplo, Geometry Nodes dibuja un recuadro alrededor de nodos in/out de simulaci√≥n. Podr√≠amos estilar los Repeat Input/Output con un borde de color especial para indicar que forman pareja de loop (si Blender permite estilizar nodos, quiz√°s con draw_buttons se puede jugar). No es cr√≠tico pero mejora UX visual.

En resumen, nuestra meta UX es que un artista familiarizado con nodos de Blender **no se sienta perdido** usando ComputeNodes. Debe reconocer patrones (menus, nombres, atajos) y encontrar algunas mejoras espec√≠ficas de este contexto (p.ej. panel de ejecuci√≥n). Al mismo tiempo, tenemos que exponer las nuevas capacidades (GLSL scripting, bucles complejos) de forma discoverable pero sin estorbar al flujo b√°sico. Evaluaremos la necesidad de un manual dedicado o incorporar ayudas in-app (tooltips detallados, mensajes de consola que orienten si algo falta, etc.). Por ejemplo, si un usuario conecta una imagen de distinto tama√±o y no inserta Resize, podr√≠amos imprimir "Nota: reescalando autom√°ticamente imagen X a tama√±o Y". Esto da transparencia y educa al usuario de la caracter√≠stica.

## **Recomendaciones T√©cnicas y Plan de Implementaci√≥n**

Para concluir, sintetizamos un **plan de acci√≥n** t√©cnico para evolucionar ComputeNodes seg√∫n lo analizado:

- **Refactorizaci√≥n Fundamental (Corto Plazo):**
- Integrar el sistema de **handlers modular** para la extracci√≥n IR, abarcando todos los nodos existentes y corrigiendo inconsistencias (especialmente Output, bucles, etc.). Eliminar el c√≥digo legacy de graph_extract_old.py una vez comprobado que la versi√≥n modular reproduce los mismos resultados[\[21\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract/registry.py#L10-L18)[\[26\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L876-L885).
- Ajustar la **arquitectura IR** para soportar recursos con dimensi√≥n variable y tama√±os independientes. A√±adir campos o tipos seg√∫n necesidad (ResourceDesc.dimensions, ResourceType.BUFFER, etc.). Asegurar que _schedule_passes_ no asume ya un solo tama√±o global (preparar terreno para pr√≥ximo paso).
- Reforzar el **TextureManager** y **ShaderManager** para manejar texturas 1D/3D: m√©todos como ensure_internal_texture(name, desc) deben contemplar dimensiones 1 o 3 (ya sea creando GPUTexture((w,), format=‚Ä¶) o GPUTexture((x,y,z), format=‚Ä¶) seg√∫n caso). Probar estos con peque√±os tests unitarios (simulando creaci√≥n de 1D y 3D como en test_texture_manager_internal[\[53\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py#L94-L102)).
- **Kernels 1D/3D y Nuevos Tipos de Recurso (Mediano Plazo):**
- Implementar el **soporte 1D/3D** en la generaci√≥n GLSL. Posiblemente esto implica variantes de ciertos emisores (p.ej., la operaci√≥n IMAGE_LOAD deber√° emitir imageLoad(img, coord_x) si es 1D, imageLoad(img, ivec3(x,y,z)) si 3D). Podemos codificar esto con chequeos en el emitter en base al tipo de ResourceDesc vinculado.
- Desarrollar nodos **Input/Output para Part√≠culas** y **Vol√∫menes**. Esto incluye la l√≥gica de conversi√≥n de datos Blender a recurso GPU y viceversa. Comenzar con casos sencillos: _Particles Input_ que solo lee posiciones como vector3 y los env√≠a a GPU (dejando velocidades u otros atributos para despu√©s), _Volume Input_ que lee densidad de un grid est√°tico. Verificar rendimiento con datasets peque√±os antes de escalar.
- A√±adir **opcodes IR** si faltan para manipular buffers (aunque quiz√° no se necesiten espec√≠ficos m√°s all√° de READ/WRITE, ya existentes).
- **No exponer SSBO a√∫n**: utilizar texturas 1D bajo el cap√≥, pero dise√±ar la API de tal modo que, cuando se habilite GPUStorageBuffer, podamos intercambiar implementaci√≥n sin cambiar la interfaz del nodo. (Por ejemplo, un socket "Buffer" seguir√° funcionando, solo que en vez de textura usar√≠a SSBO internamente).
- **Bucles y Flujo de Control Avanzado (Mediano Plazo):**
- Extender los nodos **Repeat Input/Output** para soportar m√∫ltiples variables. Internamente, reestructurar la construcci√≥n IR del loop (LOOP_START/END) para manejar listas de valores (podemos implementarlo primero con 1-2 variables para validar, luego generalizar N variables).
- Implementar **Ping-Pong**: quiz√° inicialmente como un nodo separado "PingPong Loop" para experimentar. Ensayar la t√©cnica de iterar via m√∫ltiples dispatch en Python: e.g., en execute_compute_tree, detectar un PingPong node y realizar un bucle for i in range(n): dispatch shader, intercambiar bindings, dispatch shader,‚Ä¶. Evaluar sincronizaci√≥n (¬ønecesita gpu.compute.barrier()? Blender no expone barrera, pero cada dispatch es secuencial en Python).
- Implementar nodo **Resize** (y quiz√° _Rotate/Translate_) para tener herramientas de manipulaci√≥n de resoluci√≥n.
- Ajustar _schedule_passes_ para cortes por resoluci√≥n. Testear con combinaciones: una rama half-res mezclada con full-res, etc., confirmando que efectivamente genera dos passes y que el shader del segundo puede acceder a la textura producida en el primero.
- Probar un bucle multi-res manual: por ejemplo, usar Repeat + dentro de loop un Resize a 50% -> procesar -> escalar de vuelta; asegurar que el scheduler organiza bien las passes.
- **Nodo de Scripting y Extensibilidad (Mediano - Largo Plazo):**
- Introducir **ComputeNodeScript** en Blender con un editor simple. Empezar soportando un caso b√°sico (p.ej. una entrada float, una salida float, con c√≥digo trivial) para montar la infraestructura: handler IR (que guarda el c√≥digo en alg√∫n sitio), emitter GLSL (que inyecta el c√≥digo).
- Desarrollar un mecanismo de **reemplazo de placeholders** en el c√≥digo de usuario: decidir sintaxis (in0, out0 o usar nombres personalizados). Implementar un parser muy b√°sico o sustituci√≥n de texto con precauci√≥n para no reemplazar adentro de palabras.
- Integrar la captura de errores de compilaci√≥n: forzar un error deliberado en un script para ver qu√© arroja gpu.shader.create_from_info y c√≥mo capturarlo (v√≠a try/except ya presente[\[54\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L92-L100), complement√°ndolo con el log).
- A√±adir documentaci√≥n contextual: un tooltip o modal en el UI del Script Node con instrucciones/resumen de variables disponibles, para guiar al usuario.
- Extender el **registry** para nodos custom de terceros: esto puede posponerse, pero se puede planear que tras estabilizar las partes anteriores, ofrezcamos funciones p√∫blicas para registro.
- **Mejoras de UX y pulido final (Largo Plazo):**
- Habilitar **node grouping** y verificar su funcionalidad. Si presenta trabas, coordinar con Blender dev (posiblemente ComputeNodeTree necesita marcar bl_idname = "ComputeNodeTree" con ciertas flags para que NodeGroup pueda usarse).
- Introducir **Viewer Node/backdrop**: implementar un ComputeNodeViewer que copie su entrada a un bpy.data.images\["Viewer Compute"\] cada vez que se ejecuta el tree. Configurar el Node Editor para usar backdrop con esa imagen (si t√©cnicamente posible). Esta caracter√≠stica, aunque no esencial, acercar√≠a la UX a la del Compositor, muy √∫til para depurar visualmente.
- Revisar **rendimiento UI**: si auto-exec est√° activado, que no recalcule excesivamente. Podr√≠amos agregar peque√±as demoras (debounce) si detectamos r√°faga de cambios. Blender 4.x tiene un _flag_ NodeTree.changed y quiz√°s un timer interno, pero si no, podr√≠amos manualmente controlar.
- Garantizar que todas las interacciones (mute, delete, undo, reordenar nodos) funcionan correctamente sin errores. Si encontramos edge cases (ej. al eliminar un nodo Output mientras autoexec est√° on se lanza error porque faltan outputs - podr√≠amos manejarlo con un chequeo en execute_compute_tree[\[55\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L86-L94) ya presente).
- **Testing con usuarios**: una vez todas las funcionalidades integradas, realizar pruebas comparativas: rehacer con ComputeNodes alg√∫n ejemplo hecho en Houdini Copernicus (obviamente dentro de lo que aplican: por ejemplo, un blur multires, una comp b√°sica) para verificar que nuestra UX y resultado coinciden con expectativas. Ajustar detalles seg√∫n feedback.

Por √∫ltimo, mantenernos al d√≠a con la evoluci√≥n de Blender: Blender 5.x podr√≠a traer cambios en GPU API (transici√≥n completa a Vulkan, deprecaci√≥n de GLSL). De hecho, en Blender 4.5 hay discusiones sobre GPUShaderCreateInfo y c√≥mo manejar la creaci√≥n de shaders multiplataforma[\[31\]](https://devtalk.blender.org/t/python-shadercreateinfo-missing-in-blender-4-5-what-s-the-plan/42007#:~:text=plan%3F%20devtalk,don%27t%20work%20under%20Vulkan). Nuestro dise√±o usando gpu.shader.create_from_info seguir√° vigente, pero debemos testear en cada versi√≥n alpha. Tambi√©n, si Blender introduce oficialmente _Compute Nodes_ (nativo), habr√≠a que diferenciar nuestro addon o integrarlo. Hasta entonces, este plan posiciona a **ComputeNodes addon** como una herramienta potente, flexible y m√°s alineada con est√°ndares de la industria (Houdini/Nuke), a la vez que se integra de forma coherente con la experiencia Blender.

**Fuentes:** Este plan se fundamenta en el an√°lisis del c√≥digo actual del addon (definiciones de nodos, IR y ejecuci√≥n)[\[41\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L920-L928)[\[1\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L46-L55), en las pr√°cticas comprobadas de sistemas nodales existentes (Houdini Copernicus[\[10\]](https://tokeru.com/cgwiki/HoudiniCops.html#:~:text=%2A%20New%20cops%20flow%20left,back%20to%20the%20viewport%20live)), y en capacidades confirmadas de la API de Blender a fecha de hoy[\[8\]](https://devtalk.blender.org/t/suggestions-feedback-on-the-extensions-for-the-gpu-module/17706/79?u=fclem#:~:text=Suggestions%20%2F%20feedback%20on%20the,sake%2C%20maybe%20something%20like). Cada recomendaci√≥n t√©cnica ha sido cuidadosamente evaluada para asegurar su viabilidad y beneficio dentro del contexto de Blender 5.0+. Con estas implementaciones, ComputeNodes evolucionar√° de un MVP experimental a un **sistema de producci√≥n** vers√°til comparable a soluciones profesionales, aprovechando al m√°ximo las posibilidades de c√≥mputo GPU en Blender.

[\[1\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L46-L55) [\[2\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L56-L64) [\[42\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L64-L71) [\[50\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L120-L128) [\[51\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L76-L80) [\[52\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L38-L46) [\[54\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L92-L100) [\[55\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py#L86-L94) operators.py

<https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/operators.py>

[\[3\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L801-L810) [\[13\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L838-L847) [\[15\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L813-L822) [\[23\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L17-L25) [\[24\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L35-L44) [\[26\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L876-L885) [\[27\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L905-L914) [\[28\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L8-L11) [\[32\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L880-L889) [\[41\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py#L920-L928) graph_extract_old.py

<https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract_old.py>

[\[4\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/codegen/glsl.py#L88-L96) [\[19\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/codegen/glsl.py#L64-L72) [\[20\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/codegen/glsl.py#L56-L65) [\[22\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/codegen/glsl.py#L168-L176) [\[29\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/codegen/glsl.py#L148-L156) [\[38\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/codegen/glsl.py#L70-L73) glsl.py

<https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/codegen/glsl.py>

[\[5\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py#L140-L148) [\[6\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py#L150-L156) [\[30\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py#L142-L150) [\[39\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py#L85-L93) [\[40\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py#L117-L125) [\[43\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py#L80-L88) [\[44\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py#L94-L101) [\[53\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py#L94-L102) test_runtime.py

<https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/tests/test_runtime.py>

[\[7\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/planner/scheduler.py#L20-L28) scheduler.py

<https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/planner/scheduler.py>

[\[8\]](https://devtalk.blender.org/t/suggestions-feedback-on-the-extensions-for-the-gpu-module/17706/79?u=fclem#:~:text=Suggestions%20%2F%20feedback%20on%20the,sake%2C%20maybe%20something%20like) Suggestions / feedback on the extensions for the gpu module

<https://devtalk.blender.org/t/suggestions-feedback-on-the-extensions-for-the-gpu-module/17706/79?u=fclem>

[\[9\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/ir/ops.py#L100-L105) [\[16\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/ir/ops.py#L78-L86) [\[36\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/ir/ops.py#L66-L74) ops.py

<https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/ir/ops.py>

[\[10\]](https://tokeru.com/cgwiki/HoudiniCops.html#:~:text=%2A%20New%20cops%20flow%20left,back%20to%20the%20viewport%20live) Cops - Houdini and CG tips

<https://tokeru.com/cgwiki/HoudiniCops.html>

[\[11\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/control_flow.py#L114-L123) [\[12\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/control_flow.py#L132-L139) [\[14\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/control_flow.py#L115-L123) [\[33\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/control_flow.py#L30-L38) control_flow.py

<https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/control_flow.py>

[\[17\]](https://www.sidefx.com/docs/houdini/nodes/cop/index.html#:~:text=Wiring%20COPs%20together%20controls%20the,nodes%20that%20modify%20the%20data) [\[18\]](https://www.sidefx.com/docs/houdini/nodes/cop/index.html#:~:text=Image) [\[45\]](https://www.sidefx.com/docs/houdini/nodes/cop/index.html#:~:text=COP%20nodes%20provide%20real,manipulation%20within%20a%203D%20space) Copernicus nodes

<https://www.sidefx.com/docs/houdini/nodes/cop/index.html>

[\[21\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract/registry.py#L10-L18) [\[25\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract/registry.py#L11-L19) registry.py

<https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/graph_extract/registry.py>

[\[31\]](https://devtalk.blender.org/t/python-shadercreateinfo-missing-in-blender-4-5-what-s-the-plan/42007#:~:text=plan%3F%20devtalk,don%27t%20work%20under%20Vulkan) Python ShaderCreateInfo missing in Blender 4.5 what's the plan?

<https://devtalk.blender.org/t/python-shadercreateinfo-missing-in-blender-4-5-what-s-the-plan/42007>

[\[34\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/converter.py#L53-L61) [\[35\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/converter.py#L149-L157) converter.py

<https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/converter.py>

[\[37\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/ir/types.py#L4-L13) types.py

<https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/ir/types.py>

[\[46\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/input.py#L6-L14) input.py

<https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/input.py>

[\[47\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/output.py#L14-L22) output.py

<https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/output.py>

[\[48\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/math.py#L10-L19) math.py

<https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/nodes/math.py>

[\[49\]](https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/categories.py#L10-L19) categories.py

<https://github.com/pvtrcorps/ComputeNodes/blob/cb5b4d1b368e9e70e7ccbc466bd284ac0e0765f3/compute_nodes/categories.py>